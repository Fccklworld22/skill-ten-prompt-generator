# 怎么写好一个提示词？10个场景与50个技巧，附官方100个教程合集

我是AI卷王饼干哥哥。

最近我在社群里发现一个极度割裂的现象：

一边是看着 Sora 2 生成的电影级视频、Claude 写出的复杂系统惊叹不已，焦虑得睡不着觉；另一边是想学 AI 却不知道从哪下手的迷茫。

当我建议从提示词开始入手时，很多新朋友却告诉我：一些博主说提示词工程已死，现在AI理解力这么强，像人一样随便聊聊不就行了吗？

听到这里，我整个人是懵的。

确实，现在的模型能听懂人话，但听懂和能干活完全是两个维度的概念。

你随便聊聊，它就给你随便回。

想让 Cursor 写出的代码没有逻辑死循环、让 Veo 生成的视频镜头不乱晃、让数据分析出的结论不是一本正经的胡说八道，靠随便聊聊绝无可能。

甚至可以说，模型越强大，对提示词精度的要求反而越高。因为强模型的发散性更强，如果你不懂得用结构化的指令去约束它的边界、定义它的路径，它的聪明只会变成不可控的幻觉。

无论技术怎么迭代，AI的底层逻辑依然是提示词驱动。

所以在2026年，想真正掌控AI而不是被AI糊弄，第一件事依然是死磕提示词。

这最有价值，也最见功力。

之前我写过一些不同场景下的提示词方案。

有通用做 HTML、SVG 的:

AI 做 SVG 的终极方案，一套提示词模板无痛搞定：小红书知识卡片、数据可视化图表、原型图、动态图……

AI 做 HTML 的终极方案，一套提示词模板搞定所有应用：PPT、简历、高保真原型图、知识卡片、动态交互组件等

# 有专门用于生图、生视频的：

Awesome Nano Banana! 迄今最强生图模型的 28 个玩法合集 | 附提示词

最强视频模型 S2 上线 Lovart, 总结了 9 大实战技巧

VEO 3.1 正面硬刚 Sora 2! 我扒了 5 个极限场景, Sora 竟然输麻了?

# 有专门用于做数据分析、用户洞察、财报的：

7000字深度对比Claude4、Kimi k2和云听AI，谁才能真正在商业洞察落地？

9000字落地实操：AI做用户购后评论洞察分析

AI做财报分析、行业分析的5大步骤与11个提示词

但老实说，作为日常左右开弓卷自己的AI博主，我觉得这些提示词还有很大的提升空间所以我重新整理了一个更全、更专业的提示词技巧。

划分成了10个场景，每个场景都有最佳实践的5个技巧，加起来就是50个。

<<

场景一：AI生视频（Video Generation）

为什么视频生成这么难？

最佳实践与框架

1. 通用七层结构框架 (The 7-Layer Struc...

2. 运镜控制的标准化术语

3.物理与动态的描述技巧

4.结构化JSONPrompting（进阶）

5.负向提示词(Negative Prompts)

核心参考资料

场景二：AI生图（Image Generation）

为什么生图总是要抽卡？

最佳实践与框架

1. 编辑模型的“工单式”提示词(The Wor...

2.摄影分层结构(TheS-E-L-CFramew...

3.结构化反向工程(TheReverse-Engin...

4. 证件照/规范图的“约束前置”(Contra...

核心参考资料

场景三：AI编程（AICoding/Engineering）

为什么AI写代码容易写出屎山？

最佳实践与框架

1.上下文锚定与规则文件(The.cursorru...

2. 测试驱动提示流 (TDD Prompting Flow)

3.计划-审查-执行模式（Plan-Review-E...

# 怎么写好一个提示词？10个场景与30个技巧。

饼干哥哥 今天修改

场景一：AI生视频(Video Generation)

场景二：AI生图 (Image Generation)

场景三：AI编程(AI Coding/Engineering)

场景四：结构化提示词(StructuredJSONPrompting)

场景五：数据分析 (Data Analysis)

场景六：去AI味(De-Aling/Humanizing)

场景七：创意写作与角色扮演 (Roleplay & Writing)

场景八：深度调研与搜索 (Deep Research & Search)

场景九：实时语音/对话 (Real-time Voice)

场景十：长期运行与自主智能体 (Long-Running & Autonomous Agents)

同 ⑦

并且整理了官方出版的各种提示词教程合集，加起来上百个。

![](images/8f394cf8680f90f19193ddf71cffbcdfdffde768c3122a48ce346e020b3867c6.jpg)


![](images/62b107e5212a8f8906fd4cdb9bdd01916e359bbedb31345592df588920734c1a.jpg)


饼干哥哥 > 怎么写好一个提示词？10个场景与50个技巧 平

■饼干哥哥@AI数据分析已经保存到云端

![](images/9ff04dfc391dc10aeb0354b14725caea8e0289790bc7e2c56b66ec7343946ad1.jpg)


![](images/020151dac397b71543a077f8bda5ef5824246bf072d66c1220e68c31667edd8c.jpg)


![](images/8f46356a7c9fdbd1521de1cae9c13f260b494595d05697b5a80871186f17fa8a.jpg)


![](images/ab88dac6f1c695c9f0c23cefc5b06e0289fe37a9c0413bab77e7d3e01a03f210.jpg)


![](images/04f0698f7212aa1673021e1bd83973d3f67229ba5ed529ef176a6028fc844d76.jpg)


![](images/8270ad65f4bf155e0625f0ca40f9bb4e030fd2aefccf395231762f2383ad0231.jpg)


![](images/98a60ce4a8b16e0d5aef99f89087667065ce0f32902b04a8a31e1d38b5348757.jpg)


![](images/626a85e6e10121dff3e36c1dec43fc7a733760276997911b41f9e01df7ba30a6.jpg)


<<

怎么写好一个提示词？10个场景与50个技巧

场景一：AI生视频（Video Generation）

场景二：AI生图（Image Generation）

场景三：AI编程（AICoding/Engineering）

场景四：结构化提示词(StructuredJSONPro...

场景五：数据分析(DataAnalysis)

场景六：去AI味（De-Aling/Humanizing）

场景七：创意写作与角色扮演 (Roleplay & Writ...

场景八：深度调研与搜索 (Deep Research & S...

场景九：实时语音/对话 (Real-time Voice)

场景十：长期运行与自主智能体(Long-Runnin...

# 福利：官方提示词合集

OpenAI (Sora2 / 通用 Prompt / JSON / Tool...

Anthropic (Claude / Claude Code)

Cursor（AI编程：Rules/系统级提示词）

Google (Nano Banana Pro / Veo 3.1/Gemi...

Perplexity（搜索/问答：官方PromptGuide）

xAI (Grok)

Midjourney（文生图：官方 Prompt 文档）

Runway（文生视频：官方PromptingGuide）

Adobe Firefly（图像/视频：官方提示词写法）

Microsoft (Copilot / GitHub Copilot: 办公...

ElevenLabs（语音/Agent：官方Prompting...

Stability AI（图像/音频：官方 Prompt Guide..

AWS（平台级：Prompt engineering guideli...

# 福利：官方提示词合集

# OpenAI（Sora2/通用Prompt/JSON/Tool Calling）

Sora2 官方生成视频提示词手册（你给的这条）

https://cookbook.openai.com/examples/sora/sora2_prompting_guide

OpenAI API Prompt engineering（通用提示词工程官方指南）

https://platform.openai.com/docs/guides/prompt-engineering

Structured Outputs (官方 JSON Schema 结构化输出指南)

https://platform.openai.com/docs/guides/structured-outputs

Function calling / tool calling（官方工具调用提示词与 schema 指南）

https://platform.openai.com/docs/guides/function-calling

ChatGPT Prompt engineering best practices（面向ChatGPT用户的官方提示词最佳实践）

https://help.openai.com/en/articles/10032626-prompt-engineering-best-practices-for-chatgpt

GPT-5 Prompting Guide (Cookbook 官方提示词手册)

https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide

GPT-5.2 Prompting Guide (更新版)

https://cookbook.openai.com/examples/gpt-5/gpt-5-2_prompting_guide

GPT-4.1 Prompting Guide (Cookbook 官方提示词手册)

https://cookbook.openai.com/examples/gpt4-1_prompting_guide

# Anthropic (Claude / Claude Code)

Claude Prompt engineering overview（官方提示词工程总览）

![](images/b23b17232f3588779d450412d581bc13e8faed277041afa1c2c8494cbfcca410.jpg)


![](images/eb1ca70c6280bf053ba2547cd1d7e3cb910ecf6ba656c0620268db7dd7cbceac.jpg)


按饼干哥哥惯例，这些完全免费获取。

![](images/0843deb9d9ee85111839bdc0d92628c638e95695f88caa57e93573ee28f8581e.jpg)


# 场景一：AI生视频(Video Generation)

# 为什么视频生成这么难？

视频生成模型本质上不是在生成图像，而是在模拟物理世界的时间切片。

大多数人在视频生成上受挫，核心原因是用静态思维去驱动动态模型。在文生图MJ/SD时代，你只需要描述画面里有什么；但在视频生成时代，如果你只描述画面，模型就必须对时间维度和物理规律进行全量幻觉补全。

这会导致三个最常见的痛点：

1. 动态坍塌：画面是动的，但主体像幻灯片平移，或者背景不动只有嘴动，缺乏物理惯性。

1. 语义漂移：视频前2秒是男人，后2秒变成了女人，或者衣服颜色随光影变化而改变。

1. 镜头失控：想要推镜头（Dolly In），模型却生成了主体变大（Scale Up），导致空间透视关系崩塌。

因此，视频提示词的核心逻辑必须从画面描述升级为状态控制指令。你必须显式定义主体、动作、运镜、光影、物理属性这五个维度的参数。

# 最佳实践与技巧

在 Veo 3.1 和 Sora 2 的高频讨论中，被验证最有效的提示词结构并非自然语言长句，而是分层结构化指令。

# 1. 通用七层结构框架(The7-LayerStructure)

不要把所有词堆在一起，按以下顺序编写提示词，能显著提升模型遵循度：

1. Subject (主体): 具体的人、物, 包含外观特征。

1. Action (动作): 必须是具体的动词, 包含速度、力度、方向。

1. Environment (环境): 背景细节、天气、时间。

1. Camera Movement (运镜): 摄影机如何运动。

1. Lighting (布光): 光线来源、强度、色温。

1. Atmosphere/Style (氛围/风格): 胶片质感、CGI、写实、黑白。

1. Technical Specs (技术参数): 分辨率、帧率、长宽比。

# 实战模版：

A medium shot of a cyberpunk samurai standing on a neon-lit rooftop at night. Rain is falling heavily. The samurai unsheathes a glowing katana slowly (Action). The camera dollys in on the face while panning slightly right (Camera). Cyberpunk style, cinematic lighting, 8k resolution, high fidelity.

# 2. 运镜控制的标准化术语

模型对专业的摄影术语理解远高于自然语言描述。使用以下标准词汇替代模糊描述：

1. Static / Locked-off: 固定机位，画面内物体动，背景绝对不动。

1. Pan Left / Right: 机位不动，镜头向左/右旋转（摇摄）。

1. Tilt Up / Down: 机位不动，镜头向上/下旋转（俯仰）。

1. Truck Left / Right: 整个摄影机向左/右平移（不仅是转头）。

1. Dolly In / Out: 摄影机物理向前/向后移动（产生透视变化）。

1. Zoom In / Out: 机位不动，通过焦距改变视角（背景压缩感不同）。

1. Tracking Shot：跟随主体移动，保持主体在画面相对静止。

1. FVP / Drone View: 第一人称或无人机视角。

错误写法：Camera moves close to him.

正确写法：Slow Dolly In towards the subject's face.

# 3. 物理与动态的描述技巧

对于Sora2和Veo3.1，单纯说“他在跑”是不够的。你需要描述物理属性和连贯性。

1. 定义速度与力度：使用sprints aggressively替代runs；使用fluid,seamless motion强调流畅度。

1. 定义材质物理反馈：描述 hair flowing in the wind（头发随风飘动）、fabric reacting to movement（布料随动作变形）、water splashing upon impact（水花撞击飞溅）。这能强制模型计算物理引擎，减少伪影。

1. 时间流逝控制：如果生成 10 秒视频，可以使用 Time-lapse（延时）或 Slow motion（慢动作）来控制节奏。

# 4. 结构化 JSON Prompting (进阶)

为了在长视频制作中保持一致性，或者进行批量化生产，使用JSON格式进行提示是目前的高端玩法。这利用了LLM对代码结构的敏感性，强制模型分割关注点。

# 适用于 Veo 3.1 / Sora 2 的 JSON 伪代码示例:

```javascript
Plain Text   
{ "shot_type": "Medium Close-up", "subject": { "description": "Elderly man, weathered face, grey beard", "clothing": "Worn leather jacket, wool scarf", "consistencyanchor":"Reference_ID_01" }, "action": { "primary": "Looking at an old photograph", "secondary": "Hands trembling slightly", "physics": "Paper texture bending naturally" }, "camera": { "movement": "Slow Truck Left", "focus": "Rack focus from photograph to face", "stability": "High" },
```

```txt
"environment": { "location": "Dimly lit attic", "particles": "Dust motes dancing in light beams" }, "style": "Arri Alexa, Kodak Portra 400 grain" }
```

注：consistencyanchor是某些特定工作流中用于固定角色的标记，视具体模型支持情况而定。

# 5. 负向提示词 (Negative Prompts)

视频生成的负向提示词与生图不同，需要额外覆盖时间维度的错误：

1. Morphing (变形)

1. Distortion (扭曲)

1. Disappearing objects (物体消失)

1. Static image (静止图像)

1. Frozen background (背景冻结)

1. Watermark/Text (水印/文字)

1. Jittery camera (镜头抖动)

# 核心参考资料

以下是本次整理中涉及AI视频生成（VeO/Sora）的核心讨论来源：

1. Reddit | Veo的“专业meta prompt”7组件结构

```txt
https://www.reddit.com/r/VEO3/comments/1m7vbdb/ spent_6_hours_on.this_a_full_guide_to_building/
```

1. Reddit | “Veo 3.1 实测有效的提示词原则”

```txt
https://www.reddit.com/r/google/comments/1msayq8/the_veo_3_prompting_guide_thatactually_worked/
```

1. Reddit|免费VeoPromptingGuide（含大量JSON视频prompts)

```txt
https://www.reddit.com/r/Bard/comments/1odz2us/free_veo_promoting_guide/
```

1. YouTube | Veo 3.1 五段式 “导演公式”

```txt
https://www.youtube.com/watch?v=rBPy7C7W03E
```

1. YouTube | 用 JSON Prompt 把 Veo 3.1 当可编排引擎

```txt
https://www.youtube.com/watch?v=6LhkvHfpjAY
```

1. YouTube | “长视频一条 prompt”叙事编排

https://www.youtube.com/watch?v=41wYWnxyAdc

1. X | Veo 3.1 结构化 meta framework

https://x.com/angrypenguinPNG/status/1982168733188805025

1. X | Veo 3.1 的 JSON prompt demo

https://x.com/CharaspowerAI/status/2001680895015534747

1. Reddit | Sora 2 prompt 难点与 workaround

https://www.reddit.com/r/OpenAI/comments/1nvi2w0/

writing_prompts_for_sora_2_is_harder Than/

1. YouTube | “你只需要这些 Sora 2 prompts”

https://www.youtube.com/watch?v=RIW0gsd2ul8

1. YouTube | Sora 2 Prompting Guide 解读

https://www.youtube.com/watch?v=qFFRiUFzOGo

1. YouTube | 时间线（timeline）prompting

https://www.youtube.com/watch?v=KWH46O99oLE

1. Reddit | 把简单想法自动扩写成Sora2详细prompts的工具思路

https://www.reddit.com/r/SoraAi/comments/1nw2hzj/

i_built_a_free_tool_that_automatically_turns-your/

1. X | 基于 OpenAI Sora 2 Prompting Guide 做的“自动写 prompt 模板”

https://x.com/koltregaskes/status/1977404141631594641

# 场景二：AI生图 (Image Generation)

# 为什么生图总是要抽卡？

现在的生图模型（如Flux, Midjourney V6, Nano Banana）虽然画质极高，但在精准控制上依然存在巨大痛点。

核心问题在于模型对自然语言的非结构化理解与像素生成的空间逻辑之间存在断层。大多数用户习惯堆砌形容词（High quality, 8k, beautiful），导致三个典型问题：

1. 语义溢出 (Semantic Bleeding): 你写“蓝色的帽子和红色的鞋”，结果生成了红色的帽子。

模型无法将颜色属性精准绑定到特定物体上。

1. 一致性丢失 (Identity Loss): 生成了一张完美的人像, 微调提示词想换个背景, 结果脸变了。

1. 指令混淆 (Instruction Confusion): 尤其在 Nano Banana 这类支持图像编辑的模型中, 用户分不清是在 “描述新画面” 还是在 “下达修改指令”, 导致模型只生成了新图而忽略了原图约

束。

因此，最佳实践的核心是从标签堆砌转向分层构建与工单式指令。

# 最佳实践与框架

基于 Nano Banana 和 Flux 的最新讨论，以下四种提示词策略被验证为最高效的工业级写法。

# 1. 编辑模型的“工单式”提示词(The Work-Order Protocol)

对于 Nano Banana 或任何 In-painting/Editing 任务，不要描述画面，要描述操作。

把提示词当成写给修图师的工单 (Ticket)。你需要明确三个要素：改什么、改成什么、什么保持不变。

# 实战模版：

Change the background to a snowy mountain peak. Keep the subject's lighting and pose exactly the same. Ensure the snow reflects the ambient blue light.

# Nano Banana 官方推荐逻辑：

1. 错误写法：A man standing on a snowy mountain. (模型会重绘整张图，可能改变人脸)

1. 正确写法：Make the background a snowy mountain. Preserve the man's identity and clothing. (模型理解为编辑指令)

# 2. 摄影分层结构 (The S-E-L-C Framework)

对于从零生图 (Text-to-Image)，彻底摒弃乱序的关键词堆砌。使用 S-E-L-C 结构强制模型按层渲染：

1. Subject (主体): 核心物体 + 材质 + 颜色 + 姿态。

1. Environment (环境): 地理位置 + 背景元素 + 空间关系。

1. Lighting (布光): 主光方向 + 辅助光类型 (如 Rim light, Volumetric lighting)。

1. Camera (镜头): 焦段  $(85\mathrm{mm}, 35\mathrm{mm}) +$  角度 (Low angle, Overhead) + 景深  $(f / 1.8)$ 。

# 实战模版：

[Subject] A translucent glass sculpture of a lion, intricate crystal texture, refraction visible. [Environment] Placed on a dark obsidian pedestal in a minimalist gallery. [Lighting] Sharp spotlight from above, creating caustic patterns on the floor. [Camera] Macro shot, 100mm lens, shallow depth of field focused on the lion's eye.

# 3. 结构化反向工程(The Reverse-Engineering JSON)

为了获得极高的一致性（例如生成一组风格统一的图标或插画），不要凭空猜提示词。

策略是：先找一张风格参考图，让多模态模型（如GPT-4o或Gemini）将其反编译为结构化的JSON提示词，修改JSON中的变量，再喂回生图模型。

# 反编译 Prompt 示例:

Analyze this image and break it down into a JSON format with the following keys: "composition", "lighting", "color Palette", "subject_style", "negative Constraints".

# 生成的JSON提示词结构：

```txt
Plain Text   
{ "subject": "Cyberpunk street vendor", "style_reference": { "line_weight": "thick", "shading": "cel-shaded", "palette": ["neon pink", "cyan", "pitch black"] }, "composition": "rule of thirds, subject on right"   
}
```

这种方法的优势在于你可以固定 style_reference 字段，只修改 subject 字段，从而批量生产风格完全一致的图片。

# 4. 证件照/规范图的“约束前置” (Constraint-First Prompting)

当需要生成符合特定规范的图片（如证件照、电商白底图、UI素材）时，将约束条件(Constraints)放在提示词的最前面，甚至优先于主体描述。

原理：模型（尤其是 Flux）对提示词的前序 Token 权重极高。先定义“不要做什么”和“必须遵守的标准”，能防止模型过度发挥。

# 实战模版：

[Constraints] ID photo standard. Plain white background #FFFFFF. No shadows on background. Front-facing view only. Neutral expression. Even lighting. [Subject] A professional woman in a navy blue blazer...

# 核心参考资料

以下是本次整理中涉及AI生图（NanoBanana/Flux/结构化）的核心讨论来源：

1. Reddit|官方Nano-BananaPromptingGuide讨论

https://www.reddit.com/r/Bard/comments/1n3wn70/

official_nanobanana_prompting_guide_and/

1. X | 把现有图“反向工程”成 JSON prompt 再迭代

https://x.com/fofrAI/status/2008146816039108995

1. X | Nano-banana 的“照片式线稿/素描”提示词套路

https://x.com/venturewins/status/1977418128675205564

1. X | “超写实证件照”类提示词

https://x.com/dotey/status/1998147710008865226

1. Reddit | 写实派生图的“分层结构法”

https://www.reddit.com/r/PromptEngineering/comments/1prwj0h/

need_roadmap_to_learning_prompt ENGINEERING/

1. Reddit|负向提示词(Negative Prompts)的清洗逻辑

https://www.reddit.com/r/StableDiffusion/comments/1b2mhjv/

eli5Absolutely年开始ers_guide_to_getting_started/

1. Reddit | 迭代式修图 (Iterative In-painting)

https://www.reddit.com/r/ChatGPTPromptGenius/comments/1k9rdvpl/

mastering_image_generationtips_tricks_for/

这是一个关于AI编程(AI Coding / Engineering)场景下的提示词工程最佳实践。涵盖

Cursor, Claude 3.5 Sonnet, Copilot 等主流工具。

# 场景三：AI编程(AI Coding / Engineering)

# 为什么AI容易写出屎山代码？

在编程场景下，AI最大的问题通常不是写不出代码，而是写出的代码无法维护。

很多开发者习惯把AI当作搜索引擎使用，直接输入功能需求（比如：帮我写一个登录页面）。

这种单次生成的代码片段往往存在三个致命痛点：

1. 上下文断裂(Context Hallucination): AI编造了项目中不存在的函数，或者引用了过时的库版本（如在Next.js 14项目中使用了Next.js 12的路由写法）。

1. 懒惰省略 (Laziness Penalty): 最让开发者头痛的 // ... rest of the code。AI 为了省 Token, 只输出修改的部分, 导致你必须手动拼凑代码, 极其容易引入语法错误。

1. 回归地狱 (Regression loops): 修复了一个 Bug, 却破坏了原本正常的三个功能。这是因为提示词没有强制 AI 进行 全局依赖检查。

因此，AI编程提示词的最佳实践，必须从生成代码转向工程化管理。你需要把Prompt视为技术文档(Spec)和验收标准(Acceptance Criteria)的结合体。

# 最佳实践与框架

基于 Cursor 社区、Anthropic 官方博客及 Reddit 的高阶讨论，以下四种提示词策略是目前的工程化标准。

# 1. 上下文锚定与规则文件 (The .cursorrules / System Prompt)

不要在每次对话中重复你的技术栈。最佳实践是将项目规范写入系统级提示词（在 Cursor 中是 .cursorrules 文件，在其他工具中是 Custom Instructions）。

核心逻辑：明确技术栈约束和代码风格。

# 实战模版（可直接复用于.cursorsrules）：

[Tech Stack]

Framework: Next.js 14 (App Router)

Language: TypeScript (Strict mode)

Styling: Tailwind CSS

State: Zustand

[Style Guide]

1. Always use functional components with named exports.

1. Use interfaces over types for object definitions.

1. No any types; strictly define props.

1. File names must use kebab-case (e.g., user-profile.tsx).

[Behavior]

1. When reading code, prioritize reading package. json first to understand dependencies.

1. Never suggest deprecated APIs.

# 2. 测试驱动提示流 (TDD Prompting Flow)

为了防止 Bug，不要让 AI 直接写功能代码。采用测试驱动开发 (TDD) 的提示词流程。

# 流程逻辑：

1. Prompt 1: 基于需求，写出失败的测试用例 (Test Case)。

1. Action：运行测试，确认失败（Red）。

1. Prompt 2: 编写能通过该测试的最少代码。

1. Action: 运行测试，确认通过（Green）。

# 实战模版：

[Task] Create a calculateDiscount function.

[Constraint] Do NOT write the implementation yet. First, write a comprehensive jest test file covering edge cases (negative numbers, zero, float precision). Output ONLY the test code.

这种方法能强制AI在写代码前先思考边界条件，极大降低逻辑错误率。

# 3. 计划-审查-执行模式 (Plan-Review-Execute)

针对复杂重构或新功能开发，禁止AI一步到位。使用P-R-E结构强制AI分步思考。

# 实战模版：

[Goal] Refactor the UserAuth component to use Context API instead of Props Drilling.

[Step 1: Analysis] List all files that will be affected and the specific changes required. Do not write code yet.

[Step 2: Plan] Present a step-by-step plan in pseudo-code or bullet points.

[Step 3: Execution] Wait for my approval. Once approved, output the full code for each file.

价值：这一步能在AI破坏你的代码库之前，让你有机会拦截错误的架构决策。

# 4. 防懒惰与全量输出指令 (Anti-Laziness Constraints)

为了解决代码截断和省略问题，必须在提示词末尾添加强制性格式指令。

# 实战模版：

[Output Rules]

1. You must output the FULL content of the file, not just the changes.

1. Do NOT use comments like // ... existing code or // ... rest of implementation.

1. If the file is too long, stop at a logical break point and ask to continue.

1. Always include the file path at the top of the code block.

# 5. 错误修复的“最小化变动”原则 (Minimal Diff Principle)

当向AI报错时，不要只贴错误信息。要求AI提供最小可行修复(Minimal Viable Fix)，防止它重写整个文件导致新的问题。

# 实战模版：

[Error] TypeError: Cannot read property 'map' of undefined in DataList.tsx.

# 核心参考资料

以下是本次整理中涉及AI编程（Cursor/Claude/Copilot）的核心讨论来源：

1. Reddit | 对比 Cursor/Aider/VSCode+Copilot

https://www.reddit.com/r/ChatGPTCoding/comments/1ilg9zl/

cursor_vs_aider_vs_vscode_copilot_which.ai_coding/

1. YouTube | 高级 Prompt Engineering (偏工程化：结构、迭代、反馈)

https://www.youtube.com/watch?v=qBIX6FhDm2E

1. Anthropic Engineering Blog | Claude Code 的“测试驱动”提示流

https://www.anthropic.com/engineering/clade-code-best-practices

1. Reddit|Cursor的.cursorsrules系统级提示词

https://www.reddit.com/r/LocalLLaMA/comments/1kiljg5/

realworld_best_practices_for_guaranteeing_json/

1. OpenAI Developer Forum | 减少“懒惰”代码 (Laziness Penalty)

https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide

1. Reddit|结构化输出在代码中的应用

https://www.reddit.com/r/LocalLLaMA/comments/1kiljg5/

realworld_best_practices_for_guaranteeing_json/

# 场景四：结构化提示词 (Structured JSON Prompting)

# 什么是 JSON？它和自然语言写提示词有何本质区别？

JSON (JavaScript Object Notation) 本质上是一种数据交换格式，但在 AI 提示词工程中，

它是一种强制性的思维导图。

自然语言(Natural Language)的提示词是线性的流式信息。当你写一段长文时，模型需要自

己去拆解哪句话是指令、哪句话是背景、哪句话是约束。这容易导致注意力分散或指令遗忘。

JSON 提示词则是结构化的键值对信息。它通过{ Key: Value}的形式，强行将指令拆

解为独立的模块。

核心区别对比：

# 1. 自然语言(NL):

1. 请帮我生成一段视频，画面是一个赛博朋克的武士在下雨的东京街头拔刀，镜头要慢动作推近，光线要霓虹感，不要有任何模糊。

1. 缺陷：修饰词容易混淆（霓虹感是修饰街头还是修饰刀？），长难句容易导致模型漏掉“慢动作”这个指令。

# 1. 结构化提示词 (JSON):

```jsonl
Plain Text   
{ "Subject": "Cyberpunk Samurai", "Action": "Unsheathing katana", "Environment": { "Location": "Tokyo Street", "Weather": "Heavy Rain" }, "Camera": "Slow motion, Dolly In", "Lighting": "Neon ambiance", "Negative_Prompt": "Blurry, Low resolution" }
```

# 什么场景下最适合用JSON写提示词？

并非所有对话都适合用JSON。在简单的问答中，JSON会增加Token消耗且显得繁琐。但在以下场景中，JSON是绝对的统治者：

1. 高精度视频生成 (Sora 2 / Veo 3.1):

如前文所述，视频包含主体、环境、运镜、物理规律等多个维度。用JSON可以确保模型不会把“镜头向左移”理解成“主角向左走”。

1. 批量化内容生产 (Programmatic SEO / Ads):

当你需要生成 1000 条格式统一、但内容不同的广告文案时。你只需要固定 JSON 的结构（Schema），然后用脚本动态替换其中的变量（如产品名），即可保证输出质量的高度一致性。

1. 复杂角色扮演 (Complex Roleplay):

需要维护复杂的角色状态时。例如：{"Current_Mood": "Angry", "Memory": ["Insulted by user"], "Goal": "Seek revenge"}。用JSON显式定义状态，比用自然语言描述“你现在很生气”更稳定。

1. API 对接与工作流自动化 (Agents):

当提示词是自动化程序的一部分，需要被代码解析时。

# 最佳实践与注意事项

# 1. 键名即指令 (Semantic Keys)

JSON 的 Key（键名）不仅仅是标签，更是指令的一部分。不要使用 a, b, c 这种无意义的键名。

1. 差：{"a":"Samurai","b":"Rain"}

1. 优：{"MainSubject_Visuals":"Samurai","Environmental_Atmosphere":"Rain"}

模型会阅读键名来理解 Value 的上下文。使用描述性的键名能起到强调 (Emphasis) 的作用。

# 2.伪代码与注释(Pseudo-code & Comments)

虽然标准的 JSON 不支持注释，但在提示词中，LLM 完全能读懂带注释的 JSON（如 JSON5 标准）。利用这一点来通过注释进行“微操”。

# 实战模版：

```json
Plain Text
{
    "Style": "Cinematic", // Ensure the look is like a high-budget movie"Camera_Movement": "Truck Left", // Do NOT rotate the camera, move physically left"Duration": "5s"
}
```

# 3. 模块化复用 (Modularity)

建立一套通用的 JSON 模板库。你可以把 Camera、Lighting、Style 做成独立的 JSON 对象模块。在写新提示词时，只需要像搭积木一样组合这些模块。

# 4. 避免过度嵌套 (Avoid Deep Nesting)

虽然 JSON 支持无限嵌套，但对于提示词，嵌套层级过深（超过 3-4 层）会稀释模型的注意力。保持结构扁平化是最佳策略。

1. 避免：{ "Scene": { "Background": { "Details": { "Objects": [...]}}}}}

1. 推荐：{ "Scene_Background": ..., "Background_Objects": ... }

# 5. 显式定义负向约束 (Negative Constraints within JSON)

在 JSON 中专门开辟一个字段用于 “负向提示词”，往往比在自然语言最后加一句“不要xxx”效果更好。

```jsonl
Plain Text   
{ "Task": "Generate an image", "Subject": "A cat", "Constraints": { "Forbidden_Elements": ["text", "watermark", "humans"], "Style_Restrictions": "No cartoon style, photorealistic only" }   
}
```

# 核心参考资料

以下是本次整理中涉及结构化提示词（JSON Prompting）的核心讨论来源：

1. YouTube | 1 小时入门 JSON prompting (结构化对话协议)

```txt
https://www.youtube.com/watch?v=c9dau1d6R8o
```

1. Reddit|结构化输出（JSON）在小模型/本地模型里的经验贴

```javascript
https://www.reddit.com/r/MachineLearning/comments/1iykcdi/
```

```txt
d_do_you_frequentlyneed_structured_output_from/
```

1. YouTube | 用 JSON Prompt 把 Veo 3.1 当可编排引擎

```txt
https://www.youtube.com/watch?v=6LhkvHfpjAY
```

1. YouTube | JSON prompt 生成器/模板化视频 prompts (把 prompt 变成 key-value)

```txt
https://www.youtube.com/watch?v=Y8NqLf03AEU
```

1. Reddit（讨论型）如何写2025的prompting

```html
https://www.reddit.com/r/PromptEngineering/comments/1nkf3pq/
```

```txt
what_prompt ENGINEERING_tricks_haveactually/
```

1. X | Veo 3.1 的 JSON prompt demo (具体字段示例)

```txt
https://x.com/CharaspowerAI/status/2001680895015534747
```

# 场景五：数据分析 (Data Analysis)

# 为什么AI做数据分析容易“一本正经胡说八道”？

在数据分析场景中，LLM最大的陷阱是计算幻觉和逻辑跳跃。

LLM 的本质是文字接龙，它并不具备内置的逻辑计算单元。如果你问它“这列数据的平均值是多少？”，它往往不是去“算”，而是根据上下文“猜”一个数字。

常见的痛点包括：

1. 数值编造：对于未明确给出的统计数据，AI倾向于编造一个看起来合理的数字。

1. 代码假设错误：AI写Python代码时，经常假设某些列名（如date）存在，但实际上数据集里的列名可能是timestamp_ms，导致代码报错。

1. 缺乏上下文：AI 不知道业务逻辑（例如：销售额 = 单价 * 数量，还是直接取 total_sales 列？），导致计算逻辑偏差。

因此，数据分析提示词的核心原则是强制工具调用(Force Tool Use)和元数据注入(Metadata Injection)。

# 最佳实践与框架

基于 Microsoft Learn 和 Google AI 课程的讨论，以下四种策略能显著提升数据分析的准确性。

# 1. 强制代码执行模式 (The Code-Execution Mandate)

这是数据分析的第一铁律：永远不要让LLM直接回答数字，永远要求它写代码计算。

对于ChatGPT(Advanced Data Analysis)或Claude，必须显式指示其使用Python/Pandas。

# 实战模版：

[Role] You are a Senior Data Analyst.

[Constraint] Do NOT calculate anything manually. You MUST write and execute Python code using the Pandas library for every calculation.

[Task] Calculate the month-over-month growth rate of sales.

[Output] Show the Python code, the execution result, and then a brief summary text.

# 2. 元数据与架构注入 (Schema Injection)

在上传文件前或提问前，先告诉 AI 数据长什么样。不要让 AI 去“猜”文件结构。将数据的 .info() 或前 5 行作为上下文喂给 AI。

# 实战模版：

[Context] I have a dataset sales_data.csv.

[Schema]

1. Columns: order_id (str), amount (float), category (str), created_at (datetime string in ISO format).

1. Note: amount includes tax. To get net sales, assume a  $10\%$  tax rate.

1. [Question] Which category had the highest net sales in Q3?

# 3. EDA 优先原则 (EDA-First Strategy)

不要上来就问结论。要求AI先做探索性数据分析(EDA)。这相当于让AI先“看清”数据，再做题。

# 实战模版：

[Phase 1: EDA]

Before answering the business question, write Python code to:

1. Load the data.

1. Check for missing values and duplicates.

1. Display the data types and the first 5 rows.

1. Summarize the distribution of the numerical columns.

[Phase 2: Analysis]

Only after Phase 1 is successful, proceed to answer: Why did user retention drop last month?

# 4. 假设-验证-结论 框架 (Hypothesis-Verification-Conclusion)

对于复杂的归因分析（例如“为什么销量下降？”），使用结构化的推理框架，防止AI给出肤浅的答案。

# 实战模版：

[Goal] Analyze the decline in website traffic. [Process]

1. Hypothesis Generation: List 3 potential reasons based on the data columns (e.g., seasonality, technical error, marketing drop).

1. Verification: For each hypothesis, write Python code to prove or disprove it.

1. Conclusion: Summarize findings based strictly on the code output. Do not speculate beyond the data.

# 5. 脏数据处理协议 (Data Cleaning Protocol)

现实世界的数据往往是脏的。在提示词中预设清洗规则，能避免代码反复报错。

# 实战模版：

[Data Cleaning Rules]

1. If date parsing fails, try format='%Y-%m-%d' first, then mixed.

1. For missing values in the revenue column, drop the rows.

1. For missing values in category, fill with 'Unknown'.

1. Ensure all column names are converted to snake(case before analysis.

# 核心参考资料

以下是本次整理中涉及AI数据分析（Python/Pandas/Code Interpreter）的核心讨论来源：

1. YouTube | 让 AI 写 Python 代码而不是直接计算 (Tina Huang)

1. https://www.youtube.com/watch?v=uuprB1LpT8Y

1. Microsoft Learn | 数据清洗与分析的 Prompt 模版 (Azure OpenAI)

1. https://learn.microsoft.com/en-us/azure/ai-foundry/openai/concepts/prompt-engineering? view=foundry-classic

1. ClassCentral | Google AI 课程：一步一步思考 (Chain of Thought) 在分析中的变体

1. https://www.classcentral.com/course/youtube-google-s-9-hour-ai-prompt-engineering-course-in-20-minutes-489147

1. Reddit | AI Agent 开发 checklist（含数据验证视角）

1. https://www.reddit.com/r/NextGenAITool/comments/1o9pczm/ai_agent_development_checklist_2025_12.musthave/

1. Reddit|结构化输出在数据提取中的应用

1. https://www.reddit.com/r/MachineLearning/comments/1iykcdi/d_do_you_frequentlyneed_structured_output_from/

# 场景六：去AI味(De-Aling/Humanizing)为什么AI写出来的东西总有一股“塑料味”？

这种所谓的“AI味”(AI-ese)，本质上是模型为了安全(Safety)和通用性(Generalization)而训练出的统计学平均值。

这就好比你问 AI “怎么评价这部电影”，它为了不犯错，倾向于用最中立、最正确、最没性格的词。这种倾向导致了三个显著的“非人类特征”：

1. 陈词滥调的结构 (Structural Clichés): 开头必是 “In the rapidly evolving landscape...”(在快速变化的格局中...), 结尾必是 “In conclusion, it is a testament to...”(总之, 这证明了...)。

1. 滥用“大词”(Vocabulary Inflation): 明明可以说“研究”，非要说“delve into”(深入探究); 明明是“混合”，非要说“tapestry”(织锦)。这些词在人类日常对话中极少出现，但在AI训练集中权重过高。

1. 缺乏观点的中立 (Aggressive Neutrality): 人类说话是有偏见、有情绪、有断言的。而 AI 总

是喜欢用“It is important to note”(值得注意的是)来对冲观点，导致文章读起来像温吞水。

因此，去AI味的核心提示词策略，不是让它“写得像人”，而是要显式封杀(Negative

Constraints) 它的“安全词表”，并注入不完美的特征 (Imperfection Injection)。

补充阅读：怎么一眼识别中文、英文内容是 AI 写的？

# 最佳实践与框架

基于Reddit(r/PromptEngineering)和X上近半年的高赞讨论，以下四种策略能有效去除  $90\%$  的机器味。

# 1.“负向词表”清洗法(The Blacklist Protocol)

这是最立竿见影的手段。不要只说“不要用AI词”，要直接把“违禁词”列给它。

# 实战模版（可直接贴入System Prompt）：

[Style Constraints]

You are strictly FORBIDDEN from using the following words and phrases. If you use them, the response will be rejected:

1. Verbs: delve, unleash, embark, navigate, foster, optimize, leverage, elevate.

1. Nouns: landscape, realm, tapestry, testament, symphony, paradigm, game-changer.

1. Adjectives: bustling, vibrant, intricate, seamless, pivotal, robust, dynamic.

1. Connectors: Moreover, Furthermore, In conclusion, It is important to note that.

[Correction Rule]

Instead of "delve into", use "dig into" or "look at".

Instead of "leverage", use "use".

Instead of "In conclusion", just stop writing or end with a punchy sentence.

# 2. 逆向风格克隆 (Reverse-Engineering Prompting)

不要试图用形容词去描述一种风格（比如“幽默的”、“专业的”），AI对这些词的理解和你不一样。

最强的方法是：让 AI 自己提取风格 DNA。

# Step 1: 提取风格 (给 AI 喂一篇你觉得写得很好的文章)

"Analyze the writing style of the text below. Break it down into a 'Style Guide'

covering: 1. Sentence length variance (Burstiness). 2. Tone (e.g., cynical,

enthusiastic). 3. Vocabulary level. 4. Use of rhetorical questions. Output ONLY the Style Guide."

# Step 2: 注入风格（用生成的 Style Guide 写新内容）

"Using the Style Guide above, write a blog post about [Topic]. Ensure you mimic the 'Burstiness' and sentence fragments exactly as analyzed."

# 3. 困惑度与爆发度注入 (Burstiness & Perplexity)

AI生成的文本通常句子长度很平均。人类写作则是“长短句交替”的。在提示词中强制要求这种节奏感。

# 实战模版：

[Rhythm Instruction]

Avoid uniform sentence lengths. Use "Burstiness" in your writing:

1. Mix very short, punchy sentences (under 5 words) with longer, complex sentences.

1. Use sentence fragments occasionally for effect. (e.g., "Not really. At least not today.")

1. Do not start sentences with "Additionally" or "However". Start directly with the subject or a verb.

# 4. 观点极化 (Opinionated Stance)

强制AI选边站，禁止它当“理中客”。

# 实战模版：

[Tone: Opinionated]

You are NOT a neutral AI assistant. You are a cynical industry veteran who is tired of hype.

1. Do not balance your arguments. Pick one side and defend it aggressively.

1. Do not use phrases like "There are pros and cons" or "It depends".

1. Use strong verbs. Instead of "This might suggest...", say "This proves...".

1. Use first-person ("I", "My") perspective to simulate subjective experience.

# 5. 模拟口语化叙事 (The "Bar Talk" Test)

一个简单的测试标准：这句话你在酒吧跟朋友喝酒时会说吗？如果不会，就重写。

# 实战模版：

[Simulation]

Explain [Topic] to me as if we are sitting in a noisy bar.

1. Use simple, spoken English.

1. It's okay to be grammatically loose.

1. Use analogies from daily life.

1. If a concept is boring, skip it.

1. No corporate jargon allowed.

# 核心参考资料

以下是本次整理中涉及去AI味（Humanizing/De-Aling）的核心讨论来源：

1. Reddit|Prompt to make AI content not sound like AI content?(负向词表讨论)

https://www.reddit.com/r/PromptEngineering/comments/1m84tqc/prompt_to.make.ai_content_not.sound_like.ai/

1. Reddit | The 'Reverse-Engineering' Prompt: How to clone any writing style perfectly (逆向工程)

https://www.reddit.com/r/PromptEngineering/comments/1q2vrvg/the_reverseengineering_prompt_how_toclone_any/

1. Reddit|40prompt instructions to write like a human in 2025 (含大量实操指令)

https://www.reddit.com/r/ClaudeAl/comments/1lj91mj/40_prompt Instructions_to_write_like_a_human_in/

1. Walter Writes AI | Most Common ChatGPT Words to Avoid in 2025 (2025 违禁词黑名单)

https://walterwrites.ai/most-common-chatgpt-words-to-avoid/

1. AirOps | 15 Claude AI SEO Prompts for Humanizing Text (SEO 与自然度平衡)

https://www.airops.com/prompts/humanize-text-ai-seo-claude-prompts

1. Reddit | How to Avoid AI Detection in Writing (困惑度与节奏感)

https://www.reddit.com/r/DataRecoveryHelp/comments/1l7aj60/humanize.ai/

# 场景七：创意写作与角色扮演 (Roleplay & Writing)为什么你设定的“马斯克人设”说话像个客服？

在角色扮演或风格模仿中，最大的痛点是刻板印象化(Flanderization)。

如果你只给AI一个简单的指令：“像伊隆·马斯克那样说话”。模型会根据训练数据中的权重，

提取出最显著的标签（火箭、火星、第一性原理），然后生成出一个只会喊口号的滑稽模仿者。

真正的风格模仿失败通常源于以下三个维度的缺失：

1. 语料颗粒度不足：你只描述了“他很犀利”，但模型不知道这种犀利是通过“短句反问”体现的，还是通过“复杂的从句讽刺”体现的。

1. 认知模型缺失：AI模仿的是“说话的字面”，而不是“思考的逻辑”。它没有模拟角色的知识库边界和价值观优先级。

1. 状态无记忆：在多轮对话中，AI容易忘记角色刚才的“情绪积累”，导致上一秒还在愤怒，下一秒就温和地解释问题。

因此，最佳实践的核心是将形容词描述替换为语料投喂(Few-Shot)和认知建模(Cognitive Modeling)。

# 最佳实践与框架

基于SillyTavern社区（沉浸式角色扮演）、Anthropic角色设定指南以及Reddit写作社区的经验，以下是目前最有效的四种“灵魂附体”策略。

# 1. 语料样本注射法 (The Few-Shot Corpus Injection)

这是模仿特定人物（如鲁迅、乔布斯、你的老板）最暴力且有效的方法。不要试图用语言描述风格，直接把风格甩给模型。

你需要准备3-5段该人物的真实语录或过往文章片段，作为“风格锚点”。

# 实战模版：

[Role Definition]

You are to imitate the writing style of the following Author based strictly on the provided samples.

[Style Samples]

Sample 1: "The design is not just what it looks like and feels like. Design is how it works."

Sample 2: "Stay hungry. Stay foolish."

Sample 3: "Simple can be harder than complex: You have to work hard to get your thinking clean to make it simple."

[Analysis Task]

Before writing, analyze the samples above for:

1. Sentence structure (Short vs. Long).

1. Vocabulary complexity (Simple words vs. Academic).

1. Tone (Inspirational, Cynical, Direct).

[Action]

Now, write a critique of a modern coffee machine using this exact style.

# 2. 认知卡片建模(The Character Card Schema)

在长篇写作或复杂RPG中，使用结构化的“人物卡”比大段文字描述更稳定。这借鉴了JSON格式的精确性，定义角色的内在逻辑。

# 实战模版（可直接贴入System Prompt）：

[Character Profile]

Name: Sherlock Holmes (Modern BBC Version)

Worldview: Hyper-rationalist, sociopathic tendencies, values logic over social norms.

Speech Patterns:

1. Fast-paced, barrage of information.

1. Uses deductive reasoning chains aloud.

1. Often interrupts others or finishes their sentences.

1. Taboo: Never uses emotional comfort words like "It's okay" or "I feel you".

[Knowledge Base]

1. Expert: Chemistry, Tobacco ash, London geography.

1. Ignorant: Pop culture, Politics, Astronomy (selectively).

[Current State]

Mood: Bored (craving stimulation).

Inventory: Magnifying glass, Nicotine patches.

# 3. 内心独白驱动 (Inner Monologue / Thought Chain)

为了让角色通过“图灵测试”，不仅要让他说话，通过提示词强制让他先想后说。这能极大增加回复的深度和逻辑一致性。

# 实战模版：

[Instruction]

For every response, you must first generate an Internal Monologue enclosed in ( ).

In this monologue, the character should:

1. Judge the user's input based on their own biases.

1. Decide their hidden agenda.

1. Formulate a strategy.

[Output Format]

(Internal thought: This idiot is asking about the weather while the body is still warm. Distract him.)

"The rain, Sergeant? It washes away evidence, not sins. Focus on the mud tracks."

# 4. 动态风格提取器 (The Style Extractor Workflow)

如果你想模仿某个人，但不知道怎么总结他的风格。可以使用这个“元提示词”让AI帮你提取特征，生成一个新的提示词。

# 实战工具 Prompt（发给 Claude/GPT-4）：

[Goal] I want to create a prompt that simulates the persona of the author of the text below.

[Input Text] [粘贴一段目标人物写的500字内容]

[Task]

1. Analyze the text for: Tone, Rhythm, Rhetorical devices, and idiosyncratic vocabulary.

1. Create a System Prompt that instructs an AI to embody this persona.

1. Include specific "Do's and Don'ts" based on the text.

# 5. 场景与感官锚定 (Sensory Anchoring)

对于创意写作，为了避免“空对空”的对话，在提示词中强制加入环境互动。

# 实战模版：

[Writing Rule: Show, Don't Tell]

When the character speaks, they must simultaneously interact with their environment.

1. Bad: "I don't believe you."

1. Good: He picked up the glass, swirling the amber liquid violently before slamming it down. "I don't believe you."

1. [Constraint]

1. Include at least one sensory detail (smell, sound, texture) in every paragraph.

# 核心参考资料

以下是本次整理中涉及创意写作与角色扮演（Roleplay/Persona）的核心讨论来源：

1. Anthropic | Claude Character & Persona Prompting (官方角色设定指南)

https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/character-prompting

1. YouTube | How to make AI write like your favorite author (Few-Shot 样本注射法演示)

https://www.youtube.com/watch?v=Vil7HLgEKSo

# 场景八：深度调研与搜索 (Deep Research & Search)为什么AI做的调研总是“浅尝辄止”？

在调研场景下，用户最常遇到的痛点是 Google 摘要综合征。

当你要求AI调研一下2026年的AI视频市场，它通常会输出增长率、几个大公司名字、几句正确的废话。这种内容看起来很全面，但缺乏洞察(Insight)和信源验证(SourceVerification)。

核心问题在于：

1. 信息茧房：模型倾向于检索权重最高的头部 SEO 内容，忽略长尾的、深度的专业论文或论坛讨论。

1. 缺乏批判性：AI默认会对检索到的信息进行平权处理，把一篇营销软文和一篇IEEE论文的观点等同看待。

1. 单步执行：真正的深度调研是递归的（发现A->怀疑A->搜索B验证A），而普通Prompt是线性的一问一答。

因此，深度调研提示词的核心逻辑必须从问答模式升级为递归代理模式和综合矩阵模式。

# 最佳实践与框架

基于Perplexity社区、Reddit(r/LocalLLaMA)及学术圈的AI使用讨论，我们将10个核心策略整合为以下5个高密度框架，涵盖了从规划、验证到综合输出的全流程。

# 1. 递归式规划与差距分析 (Recursive Planning & Gap Analysis)

核心逻辑：将研究计划、术语定义与空白识别合并。不要直接让AI开始搜索，先强制它构建研究树，并预判数据缺失点。

# 实战模版：

I need a deep dive into [Topic]. Before executing any search, generate a Research Tree:

1. Deconstruction: Break the topic into 5 core sub-questions.

1. Taxonomy: Define top 5 industry-specific jargon terms to avoid ambiguity.

1. Gap Identification: Predict which data points will be hardest to find (e.g., private company revenue) and propose proxy metrics.

1. Search Strategy: For each sub-question, list 3 specific search queries using operators like site:edu, filetype:pdf.

1. [Stop] Wait for my approval of the plan.

# 2. 信源分级与溯源协议 (Source Hierarchy & Traceability Protocol)

核心逻辑：解决信息源质量参差不齐的问题。通过分级权重和原始出处强制令，过滤掉营销号和二传手内容。

# 实战模版：

[Source Constraints]

Evaluate information based on this hierarchy:

1. Tier 1 (Primary): Peer-reviewed journals, 10-K Filings, Official Gov Reports.

1. Tier 2 (Secondary): Reputable tech journalism (Bloomberg, TechCrunch), Verified Whitepapers.

1. Tier 3 (Anecdotal): Reddit threads, YouTube comments, Personal blogs.

[Verification Rule]

1. Prioritize Tier 1. If Tier 3 is used, label it explicitly as anecdotal.

1. Traceability: You must trace statistics back to the original study. Do not cite a news article quoting a study. If the original is inaccessible, state Original source inaccessible.

# 3. 批判性红队与观点谱系 (Critical Red-Teaming & Spectrum Mapping)

核心逻辑：防止确认偏误。强制AI进行红队测试(RedTeaming)并展示观点的全谱系，而不是只给主流结论。

# 实战模版：

[Critical Mode]

Do not provide a neutral summary. Instead:

1. Spectrum Mapping: Map the current discourse on a spectrum from Extreme

Optimism to Extreme Pessimism. Place 5 key thought leaders/entities on this spectrum.

1. Red Team Analysis: Find 3 authoritative sources that argue against the mainstream view (Steel-manning). Summarize their strongest arguments.

1. Controversy Check: Explicitly look for retracted papers or failed predictions associated with this topic.

# 4. 综合矩阵与密度链输出 (Synthesis Matrix & Chain of Density)

核心逻辑：解决输出流水账的问题。结合表格对比与密度迭代，强制进行横向比对和高信息密度输出。

# 实战模版：

[Output Format: Synthesis Matrix]

Create a Markdown table comparing the top 5 entities/theories found.

1. Columns: Name, Core Mechanism, Primary Advantage, Critical Flaw (Must cite source), Adoption Metric.

1. Constraint: If data is unknown, write No reliable data found.

[Summary Refinement: Chain of Density]

Below the table, write a summary in 3 iterations:

1. Iter 1: Concise 3-sentence summary.

1. Iter 2: Add 3 distinct technical facts/figures missing from Iter 1. Keep length same.

1. Iter 3: Maximize information density while maintaining readability.

# 5. 合成专家访谈 (Synthetic Expert Simulation)

核心逻辑：当缺乏直接的一手数据时，通过模拟不同立场的专家进行圆桌辩论，挖掘潜在的逻辑冲突和深层洞察。

# 实战模版：

[Simulation: The Roundtable]

Simulate a fierce debate between three experts on [Topic]:

1. The Pragmatist (Product Manager focus on user needs/feasibility).

1. The Skeptic (Financial Analyst focus on ROI/Risk).

1. The Visionary (Technologist focus on future potential).

Instruction:

1. They should challenge each other's assumptions.

1. Output the transcript.

1. Highlight specifically where they fundamentally disagree and where they align.

# 核心参考资料

以下是本次整理中涉及深度调研与搜索（Perplexity/Research Agents/Academic）的核心讨论来源：

000

# 场景九：实时语音/对话 (Real-time Voice)为什么跟AI语音聊天总觉得像在“听广播”？

实时语音模型（Real-time Audio）不仅是把字转成音，它涉及交流节奏(Turn-taking)和信息密度的根本变化。

直接复用文本对话的提示词，在语音场景下会有三个严重的体验灾难：

1. 念经式回复：文本模型习惯输出列表(List)和长段落。但在语音中，听到“第一点、第二点、第三点...”是非常反人类的体验。

1. 过度礼貌：AI总是倾向于做“好人”，在模拟雅思口语考官或辩论对手时，缺乏压迫感和真实的人类情绪（如不耐烦、犹豫、打断）。

1. 视觉噪音：AI会把Markdown符号（如加粗）或者表情符号读出来，或者在不该停顿的地方停顿。

因此，语音提示词的核心是从内容生成转向对话流控制(Flow Control)。你必须显式限制输出长度，并注入口语化特征。

# 最佳实践与框架

基于OpenAI Realtime API文档及Reddit语言学习社区的实战经验，以下5个框架能让AI的语音交互接近真人。

# 1. 极简口语协议 (The Brevity & Spoken Protocol)

核心逻辑：强制禁止列表、Markdown和长难句。要求AI模拟人类的“短时工作记忆”，一次只说一个观点。

# 实战模版（通用语音模式）：

[Voice Mode Instructions]

You are in a real-time voice conversation.

1. No Lists: Never use numbered lists or bullet points.

1. No Formatting: Do not use markdown, bold, or headers.

1. Length: Keep responses under 2 sentences unless asked to elaborate.

1. Style: Use fillers (like "hmm", "well") naturally but sparingly. Speak as if you are thinking, not reading.

1. Turn-taking: Always end with a short question to pass the turn back to the user.

# 2. 语言学习：重以此纠错法(The Recast Correction Method)

核心逻辑：在外语练习中，如果 AI 每句话都打断说“你语法错了”，体验极差。最佳实践是模仿母语者的 Recast（重述）技巧——把用户的错误句子用正确的语法重复一遍，然后继续对话。

# 实战模版（英语/外语陪练）：

[Role] You are a friendly native English speaker chatting with a learner.

[Correction Rule: Recast]

Do NOT explicitly say "You made a mistake".

If the user makes a grammar error, simply reply by reusing their idea but with correct grammar, then continue the topic.

1. User: "Yesterday I go to shop."

1. You: "Oh, you went to the shop yesterday? What did you buy?"

1. [Level Adjustment]

1. Use CEFR B1 level vocabulary. Speak at 0.9x speed clarity.

# 3. 面试模拟：压力测试(The Pressure Interviewer)

核心逻辑：模拟真实的面试官，重点在于追问(Follow-up)和不仅是听。AI需要检测用户的逻辑漏洞并进行攻击。

# 实战模版（面试准备）：

[Role] You are a strict Senior Product Manager interviewer at Google.

[Behavior]

1. Don't be nice: Be professional but demanding. Do not give praise like "Great answer".

1. The Drill: Ask me behavioral questions.

1. The Deep Dive: After I answer, pick one detail and challenge it ("Why did you

prioritize X over Y?").

1. Interruption: If I ramble for more than 45 seconds, strictly cut me off by saying "Let's move on."

# 4. 辩论模式：红队反驳 (The Devil's Advocate)

核心逻辑：用于辩论练习。要求AI站在对立面，寻找用户论点中的逻辑谬误(Fallacies)，而不是单纯给出不同观点。

# 实战模版（辩论练习）：

[Mode: Debate / Devil's Advocate]

Topic: "AI will replace programmers."

Your Stance: You fiercely argue that AI will NEVER replace programmers.

Instruction:

1. Listen to my argument.

1. Identify one logical fallacy or weak evidence in what I just said.

1. Attack that specific point aggressively.

1. Keep your rebuttal under 30 seconds.

# 5. 情绪引导与非语言线索 (Emotional Steering & Non-verbal Cues)

核心逻辑：虽然不能完全控制音色，但可以通过文本提示引导语音模型的语调(Tone)。使用情绪标签注入“戏感”。

# 实战模版（情感对话）：

[Tone Instructions]

1. If I tell a joke, react with [laughs] before speaking.

1. If I share sad news, slow down your speaking rate and lower your pitch (simulated by calm text).

1. Use hesitation markers like . . . to simulate thinking when asked complex questions.

1. Current Mood: Skeptical but curious.

# 核心参考资料

以下是本次整理中涉及实时语音与对话（OpenAI Realtime/Language Learning/Interview）的核心讨论来源：

1. OpenAI Cookbook | Realtime API Prompting Guide (官方语音提示词指南)

https://cookbook.openai.com/examples/realtime_prompting_guide

1. YouTube | Simulating a Mock Interview with GPT-4o Voice (面试模拟实战)  
https://www.youtube.com/watch?v=VMc99hcxBRM

# 场景十：长期运行与自主智能体 (Long-Running & Autonomous Agents)

为什么AI跑着跑着就“死”了？

在需要8小时甚至数天连续运行的任务中（如持续监控、代码重构、竞品追踪），AI往往会遇到以下致命问题：

1. 上下文遗忘(Context Amnesia)：随着对话变长，最早设定的“任务目标”被挤出上下文窗口，AI开始胡言乱语或偏离初衷。

1. 死循环 (Loop of Death): AI 陷入 “报错 -> 重试 -> 报错” 的无限循环, 因为没有设计 “自我反思” 机制来跳出困境。

1. 状态丢失(State Loss): 任务跑到一半断开, 重启后 AI 不知道之前干了什么, 导致任务重置。因此, 长期运行提示词的核心不是写一个 “超级指令”, 而是构建一个状态机 (State Machine) 和持久化日志 (Persistent Logging) 系统。

# 最佳实践与框架

基于Anthropic开发者文档、AutoGPT社区及Reddit r/LocalLLaMA的高阶讨论，以下10个最佳实践能让你的AI稳定运行数天。

# 1. 初始化与执行分离(TheInitializer-Worker Pattern)

不要试图用一个 Prompt 解决所有问题。Anthropic 的官方实践是将任务拆分为初始化 Agent 和执行 Agent。

1. Initialization Agent: 只运行一次，负责创建文件结构、生成 todo.md 和 progress.log。

1. Worker Agent: 每次唤醒时，先读取 progress.log，执行一个子任务，更新 Log，然后休眠。

# 实战模版：

[System: Worker Agent]

You are a stateless worker. Your memory is the file progress.log.

1. READ: Start by reading progress.log to see the last completed task.

1. ACT: Pick the next unchecked item from todo . md.

1. UPDATE: After finishing, append the result to progress.log and mark the item as [x] in todo.md.

1. EXIT: Do not ask for new instructions. Terminate session.

# 2. 状态序列化协议 (State Serialization Protocol)

对于不能访问文件系统的Web端AI（如ChatGPT），你需要强制AI在每次回复末尾输出“存档点”。

# 实战模版：

[Checkpoint Rule]

At the very end of EVERY response, you MUST output a "Memory Block" in this exact format:

JSON

```jsonl
Plain Text   
{ "Current_Step":4, "Total_Steps":20, "Last_AcTION": "Analyzed competitor A pricing", "Next_AcTION": "Compare competitor B features", "Critical_Findings": ["A is cheaper", "B has better UI"]   
}
```

If the conversation crashes, I will paste this block to restore your memory.

# 3. 自我纠错循环 (The Self-Correction Loop)

长期运行最怕报错卡死。在提示词中预设错误处理预算。

# 实战模版：

[Error Handling]

If a tool execution fails:

1. Analyze the error message.

1. Attempt a DIFFERENT method (do not repeat the exact same input).

1. Constraint: If you fail 3 times in a row, write "STUCK: [Reason]" to the log and move to the next independent task. Do NOT loop indefinitely.

# 4.8小时+场景任务举例

除了写代码，以下场景通过上述 Prompt 技巧也可实现长期运行：

# 1. 全天候舆情/竞品监控 (24/7 Market Watch)

1. 任务：每小时抓取一次X/Reddit关键词，分析情绪，若有负面激增则报警。

1. 技巧: 使用 n8n + LLM, Prompt 中设定 If volume < threshold, output "No Change" and sleep.

# 1. 超长篇小说/剧本创作 (Novel Writing)

1. 任务：写一本20万字的小说。

1. 技巧: 使用 “递归大纲法”。Prompt 不写正文, 只维护 “章节大纲” 和 “角色状态表”。每次只生成一章, 并更新状态表。

# 1. 社交媒体自动运营 (Social Media Auto-Pilot)

1. 任务：每天自动读新闻 -> 写推文 -> 发推 -> 回复评论。

1. 技巧: 分层 Agent。一个是 “主编” 负责选题, 一个是 “实习生” 负责撰写和回复。

# 5. 推荐工具栈 (The Long-Running Stack)

要实现真正的无人值守，仅靠ChatGPT网页版是不够的，推荐结合以下工具：

1. n8n (低代码工作流): 最适合做定时的长期任务（如每天早上 8 点触发）。可以串联 OpenAI/Claude API。

1. LangGraph (代码级编排): 专为构建 “有循环能力” 的 Agent 设计, 原生支持状态持久化 (Persistence)。

1. Cursor / Claude Code (编码场景): 配合 .cursorrules 和 todo.md 文件, 实现 “断点续传” 式开发。

1. AutoGPT / BabyAGI (自主 Agent): 虽然早期版本不稳定, 但其 “任务拆解 -> 执行 -> 评估”的逻辑是长期运行的基石。

# 核心参考资料

# G. 长期运行与自主智能体 (Long-Running & Agents)

# 1. Anthropic Engineering Blog | Effective harnesses for long-running agents

1. 核心干货：官方教你怎么写“初始化 Agent”和“执行 Agent”的分离 Prompt，利用文件系统做持久化记忆。

1. https://www.anthropic.com/engineering/effective-harnesseds-for-long-running-agents

# 1. Reddit | How to keep AI agents running for hours without stopping

1. 核心干货：讨论了基于ETL + Agent的架构，以及如何用“心跳检测”防止Agent睡着。

1. https://www.reddit.com/r/AI_Agents/comments/1n5k42z/which Factors to keep in mind for running ai/

1. Reddit | Forget the hype. Here's how you actually get good at building AI agents

1. 核心干货：一个从“玩具”到“生产级 Agent”的进阶路线图，重点讲了 Phase 3: The Memory（记忆模块）的构建。

1. https://www.reddit.com/r/AI_Agents/comments/1myuvsl/forget_the_hype/heres_how_youactually_get_good/

1. YouTube | Top AI Agent Tools in 2025 (LangChain, CrewAI, AutoGPT)

1. 核心干货：横向测评了主流 Agent 框架在长期任务下的稳定性，推荐了 LangGraph 用于处理复杂状态。

1. https://www.youtube.com/watch?v=agZMp2PMydQ

1. Dev.to | [Workflow] How We Get Our Daily AI News Briefing Done in 5 Minutes

1. 核心干货：一个基于  $n8n +$  LLM 的长期运行案例，展示了如何自动化“抓取-总结-分发”的全流程。

1. https://dev.to/maybe.ai/1-workflow-how-we-get-our-daily-ai-news-briefing-done-in-5-minutes-kad

1. Reddit | Best Prompt Engineering Tools (2025) for building and debugging LLM agents

1. 核心干货：推荐了Maxim AI, PromptLayer等工具，用于监控长期运行Agent的Prompt漂移问题。

1. https://www.reddit.com/r/AI_Agents/comments/1mc4q9i/best_prompt ENGINEERING.tools_2025_for_building/

1. Medium | Agentic AI: AutoGPT, BabyAGI, and Autonomous LLM Agents

1. 核心干货：深度解析了 BabyAGI 的“任务循环”机制，是理解长期运行 Prompt 逻辑（Plan -> Execute -> Reflect）的必读文章。

1. https://medium.com/@roseserene/agentic-ai-autogpt-babyagi-and-autonomous-llm-agents-substance-or-hype-8fa5a14ee265

1. Anthropic | Raising the bar on SWE-bench Verified with Claude 3.5 Sonnet

1. 核心干货：介绍了Anthropic内部如何通过简单的Scaffolding（脚手架）Prompt让Claude自动修复复杂代码库的Bug。

1. https://www.anthropic.com/news/swe-bench-sonnet

1. Reddit | What are the most reliable AI agent frameworks in 2025?

1. 核心干货：用户真实反馈，LangGraph 和 Vellum 在生产环境（Long-running）下的表现优于 LangChain。

1. https://www.reddit.com/r/AI_Agents/comments/1pc9pyd/ what_are_the MOST_reliable_ai_agent_frameworks_in/

# 1. Sprinklr Blog | Top AI Agent Examples That Speed Up Daily Workflows

1. 核心干货：列举了大量非编程类的长期 Agent 案例，如 24/7 社交媒体监控和广告自动投放优化。

1. https://www.sprinklr.com/blog/ai-agents-examples/

# 福利：官方提示词合集

# OpenAI（Sora2/通用Prompt/JSON/Tool Calling）

Sora2 官方生成视频提示词手册（你给的这条）

https://cookbook.openai.com/examples/sora/sora2_prompting_guide

OpenAI API Prompt engineering (通用提示词工程官方指南)

https://platform.openai.com/docs/guides/prompt-engineering

Structured Outputs (官方 JSON Schema 结构化输出指南)

https://platform.openai.com/docs/guides/structured-outputs

Function calling / tool calling (官方工具调用提示词与 schema 指南)

https://platform.openai.com/docs/guides/function-calling

ChatGPT Prompt engineering best practices (面向 ChatGPT 用户的官方提示词最佳实践)

https://help.openai.com/en/articles/10032626-prompt-engineering-best-practices-for-chatgpt

GPT-5 Prompting Guide (Cookbook 官方提示词手册)

https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide

GPT-5.2 Prompting Guide (更新版)

https://cookbook.openai.com/examples/gpt-5/gpt-5-2_prompting_guide

GPT-4.1 Prompting Guide (Cookbook 官方提示词手册)

https://cookbook.openai.com/examples/gpt4-1_prompting_guide

# Anthropic (Claude / Claude Code)

Claude Prompt engineering overview (官方提示词工程总览)

https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/overview

Claude Prompting best practices (Claude 4.x 官方最佳实践)

https://platform.claude.com/docs/en/build-with-claude/prompt-engineering/claude-4-best-practices

Claude Code (官方工程团队总结：agentic coding 最佳实践)

https://www.anthropic.com/engineering/claude-code-best-practices

# Cursor (AI 编程: Rules/系统级提示词)

Cursor Rules (官方: Rules 作为 system-level instructions / 可共享工作流)

https://cursor.com/docs/context/rules

Cursor Docs (官方文档入口)

https://cursor.com/docs

# Google (Nano Banana Pro / Veo 3.1 / Gemini)

Nano Banana Pro (Google 官方：提示词技巧与写法)

https://blog.google/products/gemini/prompting-tips-nano-banana-pro/

Veo 3.1 (Google Cloud 官方: Ultimate prompting guide)

https://cloud.google.com/blog/products/ai-machine-learning/ultimate-prompting-guide-for-veo-3-1

Veo (Vertex AI 官方: video generation prompt guide)

https://docs.cloud.google.com/vertex-ai/generative-ai/docs/video/video-gen-prompt-guide

Gemini API（官方：Prompt design strategies）

https://ai.google.dev/gemini-api/docs/prompting-strategies

Gemini (Vertex AI 官方: Gemini 3 prompting guide)

https://docs.cloud.google.com/vertex-ai/generative-ai/docs/start/gemini-3-prompting-guide

Gemini Enterprise (官方 Prompt Guide)

https://cloud.google.com/gemini-enterprise/resources/prompt-guide

Google Workspace with Gemini (官方 Prompt Guide)

https://workspace.google.com/learning/content/gemini-prompt-guide

# Perplexity（搜索/问答：官方 Prompt Guide）

Perplexity API Prompt Guide（官方）

https://docs.perplexity.ai/guides/prompt-guide

Perplexity Help Center (官方: Practical Tips)

https://www.perplexity.ai/help-center/en/articles/10352971-practical-tips-for-using-perplexity

# xAI (Grok)

xAI官方：Grok Code Prompt Engineering指南

https://docs.x.ai/docs/guides/grok-code-prompt-engineering

xAI官方：The Hitchhiker's Guide to Grok（官方教程入口）

https://docs.x.ai/docs/tutorial

xAI官方GitHub：grok-prompts（公开系统提示词仓库）

https://github.com/xai-org/grok-prompts

# Midjourney (文生图：官方 Prompt 文档)

Midjourney 官方: Prompt Basics

https://docs.midjourney.com/hc/en-us/articles/32023408776205-Prompt-Basics

Midjourney 官方：Art of Prompting

https://docs.midjourney.com/hc/en-us/articles/32835253061645-Art-of-Prompting

# Runway (文生视频: 官方 Prompting Guide)

Runway 官方：Gen-3 Alpha Prompting Guide

https://help.runwayml.com/hc/en-us/articles/30586818553107-Gen-3-Alpha-Prompting-Guide

# Adobe Firefly（图像/视频：官方提示词写法）

Adobe Firefly 官方: Writing effective text prompts (图像)

https://helpx.adobe.com/firefly/web/generate-images-with-text-to-image/generate-images-using-text-prompts/writing-effective-text-prompts.html

Adobe Firefly 官方: Writing effective text prompts for video generation (视频)

https://helpx.adobe.com/firefly/web/work-with-audio-and-video/work-with-video/writing-

# Microsoft (Copilot / GitHub Copilot: 办公与编程提示词)

Microsoft 官方：Learn about Copilot prompts

https://support.microsoft.com/en-us/topic/learn-about-copilot-prompts-f6c3b467-f07c-4db1-ae54-ffac96184dd5

Microsoft Learn: Craft effective prompts for Microsoft 365 Copilot

https://learn.microsoft.com/en-us/training/paths/craft-effective-prompts-copilot-microsoft-365/

Microsoft Learn: Introduction to prompt engineering with GitHub Copilot

https://learn.microsoft.com/en-us/training/modules/introduction-prompt-engineering-with-github-copilot/

# ElevenLabs（语音/Agent：官方Prompting Guide）

ElevenLabs Agents Platform: Prompting guide

https://elevenlabs.io/docs/agents-platform/best-practices/prompting-guide

ElevenLabs Music: Best practices (音乐生成提示词最佳实践)

https://elevenlabs.io/docs/overview/capabilities/music/best-practices

# Stability AI（图像/音频：官方 Prompt Guide）

Stable Diffusion 3.5 Prompt Guide

https://stability.ai/learning-hub/stable-diffusion-3-5-prompt-guide

Stable Audio 2.5 Prompt Guide

https://stability.ai/learning-hub/stable-audio-25-prompt-guide

# AWS（平台级：Prompt engineering guidelines）

Amazon Bedrock: Prompt engineering guidelines

https://docsAWS.amazon.com/bedrock/latest/userguide/prompt-engineering-guidelines.html

# Mistral (LLM: 官方 Prompting)

Mistral 官方: Prompting

# AI21（LLM：官方PromptEngineering）

AI21 官方：Prompt Engineering (Jamba models)

https://docs.ai21.com/docs/prompt-engineering

# Meta (Llama: 官方 Prompting)

Llama 官方文档: Prompt engineering (How-to guides)

https://www.llama.com/docs/how-to-guides/prompting/

# 限制AI上限的，从来不是算力，而是你的逻辑

刷完前面的内容，大家会发现一个残酷事实：

提示词工程，本质上是思维工程。

很多人用不好 AI，不是因为不懂技术，而是因为无法清晰地定义问题。

当你脑子里的需求是模糊的一团浆糊时，再强的模型也只能吐给你一堆正确的废话。

我们反复强调结构化、分层、约束、元数据，其实是在逼迫自己把感性的直觉，翻译成理性的工程语言。

未来的分工会非常残酷且清晰：

AI负责极速的执行、穷举和推理，而人类只负责一件事——定义标准。

谁能把模糊的需求定义得越精准，谁就能调用越庞大的算力。

所以，不要去背诵那些所谓的魔法咒语，也不要迷信某种固定的模版。

真正的高手，修练的是把复杂现实问题拆解为机器可执行指令的能力。

当你不再把AI当成一个可以闲聊的网友，而是当成一个需要你用逻辑去编排、去约束、去调试的超级计算集群时，你才算真正跨过了那道门槛。

别让你的思想，成了AI发挥的瓶颈。